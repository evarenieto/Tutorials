{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "x = np.random.randint(0,5001,[1000,20])#lower bound(inclusive), uper bound(exclusive) and the shape.\n",
    "\n",
    "# print the shape of X\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2490.398  2519.368  2530.13   2427.349  2532.251  2540.858  2483.074\n",
      "  2455.525  2591.754  2496.137  2496.115  2539.325  2502.353  2473.717\n",
      "  2491.144  2435.916  2490.961  2514.191  2466.897  2435.829]\n",
      "[ 1416.79674534  1439.74815873  1446.28111552  1441.39249381  1468.33889276\n",
      "  1436.41284102  1455.90734201  1456.42420035  1413.20104638  1469.13265644\n",
      "  1470.3090205   1441.50317286  1467.7623869   1436.00772105  1419.27452639\n",
      "  1458.44369893  1462.59031498  1434.16081125  1450.81626831  1433.06472141]\n"
     ]
    }
   ],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(x,axis=0)\n",
    "print(ave_cols)\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(x,axis=0)\n",
    "print(std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.08738392  0.82558327  1.18709287 ...,  1.40556692  0.83201645\n",
      "  -0.05151826]\n",
      " [ 0.74012169  0.83391807 -1.07387837 ...,  0.81776673  1.58262838\n",
      "   1.06776127]\n",
      " [-0.15838405 -1.28381341  0.92504146 ...,  0.4070736  -1.16134416\n",
      "   0.95890366]\n",
      " ..., \n",
      " [ 1.33159679  1.50000678  0.53576721 ...,  0.68110144 -1.1206774\n",
      "  -0.62371852]\n",
      " [-0.88396448  1.60210797 -1.12850122 ...,  1.22706532 -1.51287041\n",
      "  -0.8777196 ]\n",
      " [-0.5345848  -1.32757107  0.88355575 ...,  1.55338856  0.46946193\n",
      "  -0.76676858]]\n"
     ]
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "x_norm = ((x - ave_cols) / std_cols)\n",
    "print(x_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.31450406116e-17\n",
      "-1.72460219215\n",
      "1.72838223271\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(np.mean(x_norm))\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(np.mean(np.min(x_norm, axis=0)))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "\n",
    "print(np.mean(np.max(x_norm, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 3, 0, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[882 645 309 701 210 631  35 104 489 601 243 388 761 264 610 582 399 419\n",
      " 753 126 496 268 713 103 866 842 845 520 534  84 373 176   9 335 422 793\n",
      " 649 169 123  15 973 823 827 666 885 173 731 513 380 837 343 749 348 988\n",
      " 648 109 192 654 535 611 102 959 185 147 735 733 500 283 852 687 221 755\n",
      " 688 673 200 187 574 956 423 226 424 787 928 108 220 395 964 796 606 863\n",
      " 272 762 134 149 383 844 994 781 175  86 798 640 276 818  38 674 435 834\n",
      " 533 931 822 633 971 105  53 506 615 997 352 621 468 760 629 517 528 314\n",
      "  65 592 737 522 766 230 355 165  78 465 389 182 493 270 530 710 892 658\n",
      " 501 275 484 890 151 428 849  39 167 444   4 785 284 510 144  67 233 660\n",
      " 550 900 985 225 125 924  57 394 404  90 662  75 846 567 947 742 800 341\n",
      " 229 993 426 549 227 556 870 369 815 605 498 719 945 477 417 129 847 576\n",
      " 332 199 938 282 325 711 961 663 829 141 991 543 573 692 999 754 526 153\n",
      " 788 944 860 364 679 905 626 437 779 251 723 891 809 386 415 736 170 685\n",
      " 923 458 727 414 152 551 112 213 769 542 257 786 464 130 864  32 773 778\n",
      " 132 212 249 839  79 472 696 982 886 936 950 865 875 181 171 155  66 183\n",
      " 441 459 188 569 998 986 409  71  89 425 768 780 215 410 482 116 118  62\n",
      " 562 174 508 494 487 261 384 371   2 825  93 349 290 555 516 730 957 771\n",
      " 856 333 810  34 790 915 725 545 382 274 327 792 808 320 321 591 317 214\n",
      " 974 263  96 656 750 667 699 843 438 486 407 219 628 440 138 381 455 566\n",
      " 948 160 527   5 492 853 298  95 946 161 676  29 728 824 136 888 981 357\n",
      " 942 855 686 127 774 184 453 323 630 198 480 351 838  16 197 789 319 476\n",
      " 902 273 859 624 398 618 293 907 164 709 286 681 356 158 602 584 795 313\n",
      " 463 588   3 236  37 925 189 655 820 354   8 874 531 209 505 413 765 439\n",
      " 148 420 912 740 634 539 547 178 553 267 954 168 857 596 564 479 397 474\n",
      " 208   7 211  46  28 575 329 932 903  19 385 107 204 680  74  44 783 393\n",
      " 862 509 989 203 716 366 316 889  94 172 812 577 216 883 694 241 817 840\n",
      "  22 908 595 951 561 791 717 278 115 310 122 861 898 612  52 841 514 636\n",
      " 943 953 362 367 180 871 121 255 300 698 483  68 987 802 832  98 894 312\n",
      " 836 962 368 206 958 488 642 967   0 431 524 627 572 322 661 504 110 867\n",
      "  41 292 281 111  72 537 224  97 806 916 830 131 359 955 570 751 977 240\n",
      " 752 436 237  36 376 650 491 402 269 143 672 154 232 910 782 739  17 507\n",
      " 471 803  63 632 427 764 593 665 670 400 289 231 262 814 259 250  77  23\n",
      " 133 623 308 811 616 757   6 330 722  82 578 217 532 872 124 287 644 429\n",
      " 702 707 114  40 879 497 291 619 691 940 560 897 363 128 449  91 609 478\n",
      " 460 675 700 177 643 538 391 467 671 344 659 370 523 887  59 242 186 651\n",
      " 914 984 443  85  58 741 448 770 140 196 726 799  31 315 202 745 166 600\n",
      " 744 139 934 254 949 244 529 328  70  92 481  56 454 641  24 277 963  64\n",
      " 917 557 880 157 247 763 927 906 586 266 405 101  80 159  26 295 433 697\n",
      "  43 759 342  69 358 599 682 540 294 876 390 851 375 638 738 868 218 767\n",
      "  47 466 457 350 598 470 965 462 452 913 625 485 392 379  20 831 536 637\n",
      " 559 978 804 541  11 445 311 235 571 365  45 922 336 833 347 607 469 495\n",
      "   1 995  18 353 193 565 930  13 678  83 858 191  87 234 972 299 587 756\n",
      " 306  10 960 669 403 416 117 408 816 334 819 896 318 854 683 563 594  73\n",
      " 412  99 475 724 933 228 919 646 747 378 446 511 502 456 581 748 715 301\n",
      " 813 758 490 374 554 939  21 877 260 387 706  48 337 983 690 732 473 162\n",
      " 647 941 708  76 265 146 878 899 918 689 794 179 980 720 653 331 248 346\n",
      " 850 303 411 307 145 895 512 450  51 305 617  12 920  30 137 434 884 246\n",
      " 729 684  42 996 580 544 421  27 807 952 338 401 597  49 515 970 546 120\n",
      " 252 718 519 579 604 525 901 223  33 772 873 968  54 205 503 639 201 801\n",
      " 499 304 620 966 835 775  25 979 194 345  81 288 734  55  61 821 340 705\n",
      " 430 704 297 253 721 608 797 695 693 583 396 377 258 418 929 339 296 279\n",
      " 869 142 280 326 100 106 256 521 190 909 975 992 652 361 406  88 585 163\n",
      " 805 635 271 664 451 285 848 622 245  14 921 712 969 926 677 911 558 113\n",
      " 447 881 518 746 614 372 552 777 207 590 461 135 714 589 893 239 603 776\n",
      " 150 302 990 156 668 238  60 432 904 937 657  50 360 119 976 222 195 548\n",
      " 743 826 442 613 935 784 568 324 703 828]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = x_norm.shape\n",
    "row_indices = np.random.permutation(np.size(x_norm,0))\n",
    "print(row_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.95595787  0.89365073 -0.7910841  ...,  0.6350815   1.74322763\n",
      "   0.0915318 ]\n",
      " [ 1.70779754  0.3664752   1.05779574 ..., -0.03569404 -0.96697082\n",
      "   1.41666386]\n",
      " [-1.54178643 -0.29614068  1.40696714 ..., -0.30553826  0.9002539\n",
      "  -0.19526613]\n",
      " ..., \n",
      " [-0.615048   -0.47464412  1.25277858 ..., -1.67707204  0.28473833\n",
      "   1.69578594]\n",
      " [ 1.0824432   0.10531842 -0.44606128 ..., -0.50147166  1.26556549\n",
      "  -1.23220464]\n",
      " [ 0.6038989   0.42342961  1.43531571 ...,  1.31282976  0.06279431\n",
      "   1.24221256]]\n",
      "[[-0.95595787  0.89365073 -0.7910841  ...,  0.6350815   1.74322763\n",
      "   0.0915318 ]\n",
      " [ 1.70779754  0.3664752   1.05779574 ..., -0.03569404 -0.96697082\n",
      "   1.41666386]\n",
      " [-1.54178643 -0.29614068  1.40696714 ..., -0.30553826  0.9002539\n",
      "  -0.19526613]\n",
      " ..., \n",
      " [ 1.18055184 -1.73667039 -1.53990118 ...,  0.19161659 -1.38122038\n",
      "  -0.21620028]\n",
      " [ 0.40979908  0.41995678  1.03359574 ...,  0.87285121  0.65901039\n",
      "   0.80957334]\n",
      " [-1.58766457 -1.43175596  1.45260142 ...,  1.37000606 -1.4018984\n",
      "  -0.50160261]]\n"
     ]
    }
   ],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "# Create a Training Set\n",
    "x_train = x_norm[row_indices[:int(np.size(row_indices)*0.6)]]\n",
    "print(x_train)\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "x_crossVal = x_norm[row_indices[:int(np.size(row_indices)*0.2)]]\n",
    "# Create a Test Set\n",
    "x_test = x_norm[row_indices[:int(np.size(row_indices)*0.2)]]\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other way is:\n",
    "x_train = x_norm[row_indices[:600]]\n",
    "x_CrossVal = x_norm[row_indices[600:800]]\n",
    "x_test = x_norm[row_indices[800:1000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(x_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "\n",
    "print(x_crossVal.shape)\n",
    "# Print the shape of X_test\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
